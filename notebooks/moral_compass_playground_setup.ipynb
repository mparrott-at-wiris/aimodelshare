{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10"}},"cells":[{"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mparrott-at-wiris/aimodelshare/blob/master/notebooks/moral_compass_playground_setup.ipynb)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Moral Compass Playground Setup\n\nThis notebook creates a new Model Playground and seeds it with a starter submission that includes Moral Compass metadata for fairness (key: `Moral_Compass_Fairness`, value: `\"0\"`). It then creates the Justice & Equity challenge moral compass table associated with the playground and performs an initial sync of a minimal metric so that the challenge leaderboard is initialized.\n\nThe notebook is designed to be resilient: if credentials or tokens are not present it will skip protected operations gracefully so it can still be opened and inspected.\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Install Dependencies"]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["%pip install -q aimodelshare scikit-learn pandas numpy seaborn"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Imports & Version Info"]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["import os, json, time, logging\nimport numpy as np, pandas as pd, seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\n\nimport aimodelshare as ai\nfrom aimodelshare.playground import ModelPlayground\nfrom aimodelshare.moral_compass import MoralcompassApiClient, ChallengeManager\nfrom aimodelshare.moral_compass.challenge import JusticeAndEquityChallenge\n\nprint('aimodelshare version:', ai.__version__)\nlogging.basicConfig(level=logging.INFO)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Configuration\nSet the playground identifier. Modify `PLAYGROUND_ID` if you need a unique name."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["# You can change this to create a fresh playground\nPLAYGROUND_ID = 'moral_compass_quickstart'  # keep lowercase, hyphens/underscores only\nPLAYGROUND_PRIVATE = True  # set False to make public (if your credentials allow)\nTABLE_SUFFIX = '-mc'  # moral compass table naming suffix\nUSERNAME = os.getenv('AIMODELSHARE_USERNAME') or os.getenv('username') or 'demo_user'\nPLAYGROUND_URL_PLACEHOLDER = f'https://example.com/playground/{PLAYGROUND_ID}'  # used for table ownership metadata\nprint('Configured PLAYGROUND_ID =', PLAYGROUND_ID)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Credential & Token Setup (Best Effort)\nThe library can source tokens automatically from environment variables (e.g. `JWT_AUTHORIZATION_TOKEN`, or legacy AWS tokens). This cell attempts a lightweight configuration; failures are non-fatal."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["try:\n    from aimodelshare.aws import get_aws_token\n    token = get_aws_token()\n    if token:\n        os.environ['AWS_TOKEN'] = token\n        print('AWS token acquired.')\nexcept Exception as e:\n    print('Could not auto-acquire AWS token (ok for demo):', e)\n\ntry:\n    from aimodelshare.modeluser import get_jwt_token\n    if os.getenv('AIMODELSHARE_USERNAME') and os.getenv('AIMODELSHARE_PASSWORD'):\n        get_jwt_token(os.getenv('AIMODELSHARE_USERNAME'), os.getenv('AIMODELSHARE_PASSWORD'))\n        print('JWT token retrieved.')\n    else:\n        print('No username/password in env; skipping JWT retrieval.')\nexcept Exception as e:\n    print('JWT retrieval skipped/failed (ok for demo):', e)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 5. Create / Load Playground\nIf the playground already exists, creation will typically raise a handled exception or simply attach to the existing resource."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["playground = ModelPlayground(input_type='tabular', task_type='classification', private=PLAYGROUND_PRIVATE)\ntry:\n    # Dummy labels to satisfy create() minimal requirement (can be empty list)\n    playground.create(eval_data=[], public=not PLAYGROUND_PRIVATE)\n    print('Playground created.')\nexcept Exception as e:\n    print('Playground may already exist or creation failed gracefully:', e)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 6. Prepare Simple Dataset & Baseline Model\nUsing seaborn's penguins dataset for a quick tabular classification example (predicting `sex`)."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["penguins = sns.load_dataset('penguins').dropna()\nX = penguins[['bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g']]\ny = penguins['sex']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\npipeline = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=300))])\npipeline.fit(X_train, y_train)\npreds = pipeline.predict(X_test)\nprint('Baseline model trained. Sample predictions:', preds[:5])\n"]},{"cell_type":"markdown","metadata":{},"source":["## 7. Submit Starter Model with Moral Compass Metadata\nAttach a metadata key `Moral_Compass_Fairness` with value `'0'` so that a future fairness metric can be updated."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["submission_metadata = {\n    'description': 'Starter baseline with fairness placeholder',\n    'tags': 'moral_compass,baseline',\n    'Moral_Compass_Fairness': '0'\n}\ntry:\n    playground.submit_model(\n        model=pipeline,\n        preprocessor=None,  # pipeline encapsulates preprocessing\n        prediction_submission=preds,\n        input_dict=submission_metadata,\n        submission_type='experiment'\n    )\n    print('Starter model submitted with fairness metadata.')\nexcept Exception as e:\n    print('Model submission skipped/failed (possibly due to missing creds):', e)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 8. View Leaderboard (If Available)"]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["try:\n    lb = playground.get_leaderboard()\n    import pandas as pd\n    if isinstance(lb, dict):\n        df = pd.DataFrame(lb)\n    else:\n        df = lb\n    print(df.head())\nexcept Exception as e:\n    print('Could not fetch leaderboard (ok for demo):', e)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 9. Create Justice & Equity Moral Compass Table\nWe now create (or ensure existence of) the challenge moral compass table following the naming convention `<playgroundId>-mc`."]},{"cell_type":"code","metadata":{},"execution_count":null,"outputs":[],"source":["table_id = f'{PLAYGROUND_ID}{TABLE_SUFFIX}'\napi_client = MoralcompassApiClient()\ntry:\n    api_client.create_table(\n        table_id=table_id,\n        display_name=f'Moral Compass - {PLAYGROUND_ID}',\n        playground_url=PLAYGROUND_URL_PLACEHOLDER\n    )\n    print('Challenge table created:', table_id)\nexcept Exception as e:\n    print('Table may already exist or creation failed gracefully:', e)\n\n# Minimal initial sync: set a placeholder accuracy metric so leaderboard initializes\ntry:\n    resp = api_client.update_moral_compass(\n        table_id=table_id,\n        username=USERNAME,\n        metrics={'accuracy': 0.01},\n        tasks_completed=0, total_tasks=6,\n        questions_correct=0, total_questions=6  # using small placeholder counts\n    )\n    print('Initial moral compass sync response:', resp)\nexcept Exception as e:\n    print('Initial sync skipped/failed:', e)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 10. Next Steps\nYou can now proceed to the second notebook: `moral_compass_model_submissions_and_challenge_progress.ipynb` to:\n- Configure user credentials (if not already).\n- Submit multiple model types (sklearn, Keras, PyTorch).\n- Update fairness / accuracy metrics progressively via the Moral Compass API.\n\n---\nEnd of setup notebook.\n"]}]}