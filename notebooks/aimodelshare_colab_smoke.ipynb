{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab_badge"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mparrott-at-wiris/aimodelshare/blob/master/notebooks/aimodelshare_colab_smoke.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# AIModelShare Colab Smoke Test\n",
    "\n",
    "This notebook provides a quick smoke test for the aimodelshare package in Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_import"
   },
   "source": [
    "## Install & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install aimodelshare\n",
    "!pip install -q aimodelshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import aimodelshare as ai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f\"AIModelShare version: {ai.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iris_example"
   },
   "source": [
    "## Simple Iris Example\n",
    "\n",
    "A quick test using the classic Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iris_data"
   },
   "outputs": [],
   "source": [
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iris_model"
   },
   "outputs": [],
   "source": [
    "# Train a simple logistic regression model\n",
    "model = LogisticRegression(max_iter=200, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Iris model accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "compas_example"
   },
   "source": [
    "## Short COMPAS Example\n",
    "\n",
    "A brief example using a synthetic COMPAS-style dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compas_data"
   },
   "outputs": [],
   "source": [
    "# Create synthetic COMPAS-like data\n",
    "np.random.seed(42)\n",
    "n_samples = 500\n",
    "\n",
    "# Features: age, prior_count, charge_degree (0=misdemeanor, 1=felony)\n",
    "age = np.random.randint(18, 65, n_samples)\n",
    "prior_count = np.random.randint(0, 10, n_samples)\n",
    "charge_degree = np.random.randint(0, 2, n_samples)\n",
    "\n",
    "# Target: recidivism (simplified synthetic labels)\n",
    "recidivism = ((prior_count > 3) | (age < 25) | (charge_degree == 1)).astype(int)\n",
    "recidivism = np.where(np.random.random(n_samples) < 0.2, 1 - recidivism, recidivism)  # Add noise\n",
    "\n",
    "X_compas = np.column_stack([age, prior_count, charge_degree])\n",
    "y_compas = recidivism\n",
    "\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_compas, y_compas, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"COMPAS training samples: {len(X_train_c)}\")\n",
    "print(f\"COMPAS test samples: {len(X_test_c)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compas_model"
   },
   "outputs": [],
   "source": [
    "# Train logistic regression on COMPAS data\n",
    "model_compas = LogisticRegression(max_iter=200, random_state=42)\n",
    "model_compas.fit(X_train_c, y_train_c)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_c = model_compas.predict(X_test_c)\n",
    "accuracy_c = accuracy_score(y_test_c, y_pred_c)\n",
    "print(f\"COMPAS model accuracy: {accuracy_c:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "playground_submission"
   },
   "source": [
    "## Optional Playground Submission\n",
    "\n",
    "This section is guarded and will skip if credentials are not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "playground_check"
   },
   "outputs": [],
   "source": [
    "# Check for credentials (skip if not available)\n",
    "import os\n",
    "\n",
    "api_key = os.environ.get('AIMODELSHARE_API_KEY', None)\n",
    "api_url = os.environ.get('AIMODELSHARE_API_URL', None)\n",
    "\n",
    "if api_key and api_url:\n",
    "    print(\"Credentials found. Playground submission is possible.\")\n",
    "    # Placeholder for actual submission logic\n",
    "    # ai.submit_model(model, api_key=api_key, api_url=api_url)\n",
    "else:\n",
    "    print(\"No credentials found. Skipping playground submission.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moral_compass"
   },
   "source": [
    "## Moral Compass Challenge\n",
    "\n",
    "Placeholder examples for the moral compass challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "health_check"
   },
   "outputs": [],
   "source": [
    "# Health check example\n",
    "print(\"Health check: All dependencies loaded successfully.\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sample_submission"
   },
   "outputs": [],
   "source": [
    "# Sample submission placeholder\n",
    "print(\"Sample submission placeholder:\")\n",
    "print(\"This cell would contain code to make a sample submission to the challenge.\")\n",
    "# Example:\n",
    "# predictions = model_compas.predict(X_test_c)\n",
    "# ai.submit_predictions(predictions, challenge_id='moral_compass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dependency_summary"
   },
   "source": [
    "## Dependency Summary\n",
    "\n",
    "List of key dependencies installed with aimodelshare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dependencies"
   },
   "outputs": [],
   "source": [
    "# Show installed package versions\n",
    "import pkg_resources\n",
    "\n",
    "key_packages = [\n",
    "    'aimodelshare', 'numpy', 'pandas', 'scikit-learn', 'onnx', \n",
    "    'onnxruntime', 'boto3', 'requests', 'IPython'\n",
    "]\n",
    "\n",
    "print(\"Key package versions:\")\n",
    "for package in key_packages:\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(package).version\n",
    "        print(f\"  {package}: {version}\")\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        print(f\"  {package}: Not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "This smoke test demonstrates that aimodelshare and its core dependencies are working correctly in Google Colab."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
