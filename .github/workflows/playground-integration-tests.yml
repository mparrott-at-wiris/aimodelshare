name: Playground Integration Tests (Isolated Steps)

on:
  workflow_dispatch:
    inputs:
      test_step:
        description: 'Which step to test'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - credentials
          - data_loading
          - preprocessing
          - model_training
          - create_submit_getleaderboard

permissions:
  contents: read

concurrency:
  group: playground-integration-tests
  cancel-in-progress: true

jobs:
  test-credentials:
    if: ${{ github.event.inputs.test_step == 'all' || github.event.inputs.test_step == 'credentials' }}
    runs-on: ubuntu-latest
    timeout-minutes: 10
    env:
      USERNAME: ${{ secrets.USERNAME }}
      PASSWORD: ${{ secrets.PASSWORD }}
      AWS_ACCESS_KEY_ID: ${{ secrets.DATA_AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.DATA_AWS_SECRET_ACCESS_KEY }}
      AWS_REGION: us-east-1
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - name: Install local aimodelshare (editable) + test dependencies
        run: |
          pip install boto3 onnx onnxmltools onnxruntime Pympler scikeras shortuuid skl2onnx tf2onnx wget
          pip install -e .
          pip install pytest scikit-learn pandas numpy opencv-python-headless tensorflow pydot regex psutil IPython "PyJWT<2.0" matplotlib seaborn importlib_resources onnxscript
          pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision
      - name: Test credential configuration only
        run: |
          pytest -vv tests/test_playgrounds_nodataimport.py::test_configure_credentials --tb=long

  test-data-loading:
    if: ${{ github.event.inputs.test_step == 'all' || github.event.inputs.test_step == 'data_loading' }}
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - name: Install local aimodelshare (editable) + test dependencies
        run: |
          pip install boto3 onnx onnxmltools onnxruntime Pympler scikeras shortuuid skl2onnx tf2onnx wget
          pip install -e .
          pip install pytest scikit-learn pandas numpy opencv-python-headless tensorflow pydot regex psutil IPython "PyJWT<2.0" matplotlib seaborn importlib_resources onnxscript
          pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision
      - name: Test data loading from seaborn
        run: |
          python -c "
          import seaborn as sns
          penguins = sns.load_dataset('penguins')
          penguins_clean = penguins.dropna()
          assert 'sex' in penguins_clean.columns
          assert 'bill_length_mm' in penguins_clean.columns
          print('✓ Data loading test passed')
          "

  test-preprocessing:
    if: ${{ github.event.inputs.test_step == 'all' || github.event.inputs.test_step == 'preprocessing' }}
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - name: Install local aimodelshare (editable) + test dependencies
        run: |
          pip install boto3 onnx onnxmltools onnxruntime Pympler scikeras shortuuid skl2onnx tf2onnx wget
          pip install -e .
          pip install pytest scikit-learn pandas numpy opencv-python-headless tensorflow pydot regex psutil IPython "PyJWT<2.0" matplotlib seaborn importlib_resources onnxscript
          pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision
      - name: Test data preprocessing
        run: |
          python -c "
          import seaborn as sns
          from sklearn.compose import ColumnTransformer
          from sklearn.pipeline import Pipeline
          from sklearn.preprocessing import StandardScaler
          from sklearn.model_selection import train_test_split
          penguins = sns.load_dataset('penguins').dropna()
          X = penguins[['bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g']]
          y = penguins['sex']
          X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)
          preprocess = ColumnTransformer([('num', Pipeline([('scaler', StandardScaler())]), X.columns.tolist())])
          preprocess.fit(X_train)
          def preprocessor(d): return preprocess.transform(d)
          assert preprocessor(X_train).shape[0] == X_train.shape[0]
          print('✓ Preprocessing test passed')
          "

  test-model-training:
    if: ${{ github.event.inputs.test_step == 'all' || github.event.inputs.test_step == 'model_training' }}
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - name: Install local aimodelshare (editable) + test dependencies
        run: |
          pip install boto3 onnx onnxmltools onnxruntime Pympler scikeras shortuuid skl2onnx tf2onnx wget
          pip install -e .
          pip install pytest scikit-learn pandas numpy opencv-python-headless tensorflow pydot regex psutil IPython "PyJWT<2.0" matplotlib seaborn importlib_resources onnxscript
          pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision
      - name: Test model training
        run: |
          python -c "
          import seaborn as sns
          from sklearn.compose import ColumnTransformer
          from sklearn.pipeline import Pipeline
          from sklearn.preprocessing import StandardScaler
          from sklearn.linear_model import LogisticRegression
          from sklearn.model_selection import train_test_split
          from unittest.mock import patch

          penguins = sns.load_dataset('penguins').dropna()
          X = penguins[['bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g']]
          y = penguins['sex']
          X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)
          preprocess = ColumnTransformer([('num', Pipeline([('scaler', StandardScaler())]), X.columns.tolist())])
          preprocess.fit(X_train)
          def preprocessor(d): return preprocess.transform(d)
          model = LogisticRegression()
          model.fit(preprocessor(X_train), y_train)
          preds = model.predict(preprocessor(X_test))
          print(f'Generated {len(preds)} predictions')
          print('✓ Model training test passed')
          "

  test-playground-create-submit-deploy-leaderboard:
    if: ${{ github.event.inputs.test_step == 'all' || github.event.inputs.test_step == 'create_submit_getleaderboard' }}
    runs-on: ubuntu-latest
    timeout-minutes: 15
    env:
      USERNAME: ${{ secrets.USERNAME }}
      PASSWORD: ${{ secrets.PASSWORD }}
      AWS_ACCESS_KEY_ID: ${{ secrets.DATA_AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.DATA_AWS_SECRET_ACCESS_KEY }}
      AWS_REGION: us-east-1
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - name: Install local aimodelshare (editable) + test dependencies
        run: |
          pip install boto3 onnx onnxmltools onnxruntime Pympler scikeras shortuuid skl2onnx tf2onnx wget
          pip install -e .
          pip install pytest scikit-learn pandas numpy opencv-python-headless tensorflow pydot regex psutil IPython "PyJWT<2.0" matplotlib seaborn importlib_resources onnxscript
          pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision
      - name: Test model submission + leaderboard retrieval
        run: |
          python -c "
          import os
          import seaborn as sns, pandas as pd
          from sklearn.compose import ColumnTransformer
          from sklearn.pipeline import Pipeline
          from sklearn.preprocessing import StandardScaler
          from sklearn.linear_model import LogisticRegression
          from sklearn.model_selection import train_test_split
          from aimodelshare.playground import ModelPlayground
          from aimodelshare.playground import ModelPlayground, Experiment, Competition
          from aimodelshare.aws import set_credentials, get_aws_token
          import aimodelshare as ai
          from aimodelshare.data_sharing.utils import redo_with_write
          
          # mock user input
          os.environ["username"] = os.environ["USERNAME"] 
          os.environ["password"] = os.environ["PASSWORD"] 
          
          #Validate Username & Password
          try: 
            os.environ["AWS_TOKEN"]=get_aws_token()
            
          if "AWS_ACCESS_KEY_ID_AIMS" in os.environ:
            pass
          elif "AWS_ACCESS_KEY_ID" in os.environ:
              os.environ['AWS_ACCESS_KEY_ID_AIMS']=os.environ.get("AWS_ACCESS_KEY_ID")
          if "AWS_SECRET_ACCESS_KEY_AIMS" in os.environ:
            pass
          elif "AWS_SECRET_ACCESS_KEY" in os.environ:
              os.environ['AWS_SECRET_ACCESS_KEY_AIMS']=os.environ.get("AWS_SECRET_ACCESS_KEY")

          if 'AWS_REGION_AIMS' in os.environ:
            pass
          elif "AWS_REGION" in os.environ:
              os.environ['AWS_REGION_AIMS']=os.environ.get("AWS_REGION")
          # Validate AWS Creds 
          import boto3
          try: 
            client = boto3.client('sts', aws_access_key_id=os.environ.get("AWS_ACCESS_KEY_ID"), aws_secret_access_key=os.environ.get("AWS_SECRET_ACCESS_KEY_AIMS"))
            details = client.get_caller_identity()
            print("AWS credentials set successfully.")
          except: 
            print("AWS credential confirmation unsuccessful. Check AWS_ACCESS_KEY_ID & AWS_SECRET_ACCESS_KEY and try again.")
            return
          
          # Set Environment Variables for deploy models
          if type == "deploy_model":
            get_jwt_token(os.environ.get("username"), os.environ.get("password")) # check two different cognito functions here
            os.environ["AWS_TOKEN"]=get_aws_token()
            #create_user_getkeyandpassword() 
          penguins = sns.load_dataset('penguins').dropna()
          X = penguins[['bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g']]
          y = penguins['sex']
          X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)
          eval_labels = list(y_test)
          preprocess = ColumnTransformer([('num', Pipeline([('scaler', StandardScaler())]), X.columns.tolist())])
          preprocess.fit(X_train)
          def preprocessor(d): return preprocess.transform(d)
          model = LogisticRegression()
          model.fit(preprocessor(X_train), y_train)
          preds = model.predict(preprocessor(X_test))
          playground = ModelPlayground(input_type='tabular', task_type='classification', private=True)
          playground.create(eval_data=eval_labels, public=True)
          playground.submit_model(model=model,
                                  preprocessor=preprocessor,
                                  prediction_submission=preds,
                                  input_dict={'description':'CI test','tags':'integration'},
                                  submission_type='experiment')
          data = playground.get_leaderboard()
          # Depending on library version, this may be a dict or DataFrame; adapt assertion
          if isinstance(data, dict):
              import pandas as pd
              df = pd.DataFrame(data)
              assert not df.empty, 'Leaderboard dict converted to empty DataFrame'
              print(df.head())
          else:
              import pandas as pd
              assert isinstance(data, pd.DataFrame), 'Leaderboard did not return a DataFrame'
              assert not data.empty, 'Leaderboard DataFrame is empty'
              print(data.head())
          print('✓ Leaderboard retrieval test passed')
          "


  integration-summary:
    needs:
      - test-credentials
      - test-data-loading
      - test-preprocessing
      - test-model-training
      - test-playground-create-submit-deploy-leaderboard
      
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Summary
        run: |
          echo "=== Integration Test Summary ==="
          echo "Credentials: ${{ needs.test-credentials.result }}"
          echo "Data Loading: ${{ needs.test-data-loading.result }}"
          echo "Preprocessing: ${{ needs.test-preprocessing.result }}"
          echo "Model Training: ${{ needs.test-model-training.result }}"
          echo "Model Submission / Leaderboard: ${{ needs.test-playground-create-submit-deploy-leaderboard.result }}"
