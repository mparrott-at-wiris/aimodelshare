name: Playground Integration Tests (Isolated Steps)

on:
  workflow_dispatch:
    inputs:
      test_step:
        description: 'Which step to test'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - credentials
          - data_loading
          - preprocessing
          - model_training
          - playground_create
          - model_submission
          - deployment

permissions:
  contents: read

concurrency:
  group: playground-integration-tests
  cancel-in-progress: true

jobs:
  test-credentials:
    if: ${{ github.event.inputs.test_step == 'all' || github.event.inputs.test_step == 'credentials' }}
    runs-on: ubuntu-latest
    timeout-minutes: 10
    env:
      USERNAME: ${{ secrets.USERNAME }}
      PASSWORD: ${{ secrets.PASSWORD }}
      AWS_ACCESS_KEY_ID: ${{ secrets.DATA_AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.DATA_AWS_SECRET_ACCESS_KEY }}
      AWS_REGION: us-east-1
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - name: Install local aimodelshare (editable) + test dependencies
        run: |
          pip install boto3 onnx onnxmltools onnxruntime Pympler scikeras shortuuid skl2onnx tf2onnx wget
          pip install -e .
          pip install pytest scikit-learn pandas numpy opencv-python-headless tensorflow pydot regex psutil IPython "PyJWT<2.0" matplotlib seaborn importlib_resources onnxscript
          pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision
      - name: Test credential configuration only
        run: |
          pytest -vv tests/test_playgrounds_nodataimport.py::test_configure_credentials --tb=long

  test-data-loading:
    if: ${{ github.event.inputs.test_step == 'all' || github.event.inputs.test_step == 'data_loading' }}
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - name: Install local aimodelshare (editable) + test dependencies
        run: |
          pip install boto3 onnx onnxmltools onnxruntime Pympler scikeras shortuuid skl2onnx tf2onnx wget
          pip install -e .
          pip install pytest scikit-learn pandas numpy opencv-python-headless tensorflow pydot regex psutil IPython "PyJWT<2.0" matplotlib seaborn importlib_resources onnxscript
          pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision
      - name: Test data loading from seaborn
        run: |
          python -c "
          import seaborn as sns
          penguins = sns.load_dataset('penguins')
          penguins_clean = penguins.dropna()
          assert 'sex' in penguins_clean.columns
          assert 'bill_length_mm' in penguins_clean.columns
          print('✓ Data loading test passed')
          "

  test-preprocessing:
    if: ${{ github.event.inputs.test_step == 'all' || github.event.inputs.test_step == 'preprocessing' }}
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - name: Install local aimodelshare (editable) + test dependencies
        run: |
          pip install boto3 onnx onnxmltools onnxruntime Pympler scikeras shortuuid skl2onnx tf2onnx wget
          pip install -e .
          pip install pytest scikit-learn pandas numpy opencv-python-headless tensorflow pydot regex psutil IPython "PyJWT<2.0" matplotlib seaborn importlib_resources onnxscript
          pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision
      - name: Test data preprocessing
        run: |
          python -c "
          import seaborn as sns
          from sklearn.compose import ColumnTransformer
          from sklearn.pipeline import Pipeline
          from sklearn.preprocessing import StandardScaler
          from sklearn.model_selection import train_test_split
          penguins = sns.load_dataset('penguins').dropna()
          X = penguins[['bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g']]
          y = penguins['sex']
          X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)
          preprocess = ColumnTransformer([('num', Pipeline([('scaler', StandardScaler())]), X.columns.tolist())])
          preprocess.fit(X_train)
          def preprocessor(d): return preprocess.transform(d)
          assert preprocessor(X_train).shape[0] == X_train.shape[0]
          print('✓ Preprocessing test passed')
          "

  test-model-training:
    if: ${{ github.event.inputs.test_step == 'all' || github.event.inputs.test_step == 'model_training' }}
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - name: Install local aimodelshare (editable) + test dependencies
        run: |
          pip install boto3 onnx onnxmltools onnxruntime Pympler scikeras shortuuid skl2onnx tf2onnx wget
          pip install -e .
          pip install pytest scikit-learn pandas numpy opencv-python-headless tensorflow pydot regex psutil IPython "PyJWT<2.0" matplotlib seaborn importlib_resources onnxscript
          pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision
      - name: Test model training
        run: |
          python -c "
          import seaborn as sns
          from sklearn.compose import ColumnTransformer
          from sklearn.pipeline import Pipeline
          from sklearn.preprocessing import StandardScaler
          from sklearn.linear_model import LogisticRegression
          from sklearn.model_selection import train_test_split
          penguins = sns.load_dataset('penguins').dropna()
          X = penguins[['bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g']]
          y = penguins['sex']
          X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)
          preprocess = ColumnTransformer([('num', Pipeline([('scaler', StandardScaler())]), X.columns.tolist())])
          preprocess.fit(X_train)
          def preprocessor(d): return preprocess.transform(d)
          model = LogisticRegression()
          model.fit(preprocessor(X_train), y_train)
          preds = model.predict(preprocessor(X_test))
          print(f'Generated {len(preds)} predictions')
          print('✓ Model training test passed')
          "

  test-playground-create:
    if: ${{ github.event.inputs.test_step == 'all' || github.event.inputs.test_step == 'playground_create' }}
    runs-on: ubuntu-latest
    timeout-minutes: 12
    env:
      USERNAME: ${{ secrets.USERNAME }}
      PASSWORD: ${{ secrets.PASSWORD }}
      AWS_ACCESS_KEY_ID: ${{ secrets.DATA_AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.DATA_AWS_SECRET_ACCESS_KEY }}
      AWS_REGION: us-east-1
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - name: Install local aimodelshare (editable) + test dependencies
        run: |
          pip install boto3 onnx onnxmltools onnxruntime Pympler scikeras shortuuid skl2onnx tf2onnx wget
          pip install -e .
          pip install pytest scikit-learn pandas numpy opencv-python-headless tensorflow pydot regex psutil IPython "PyJWT<2.0" matplotlib seaborn importlib_resources onnxscript
          pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision
      - name: Test ModelPlayground create()
        run: |
          python -c "
          import seaborn as sns
          from aimodelshare.playground import ModelPlayground
          penguins = sns.load_dataset('penguins').dropna()
          eval_labels = list(penguins['sex'][:25])
          playground = ModelPlayground(input_type='tabular', task_type='classification', private=True)
          playground.create(eval_data=eval_labels, public=True)
          print('✓ Playground create test passed')
          "

  test-model-submission:
    if: ${{ github.event.inputs.test_step == 'all' || github.event.inputs.test_step == 'model_submission' }}
    runs-on: ubuntu-latest
    timeout-minutes: 15
    env:
      USERNAME: ${{ secrets.USERNAME }}
      PASSWORD: ${{ secrets.PASSWORD }}
      AWS_ACCESS_KEY_ID: ${{ secrets.DATA_AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.DATA_AWS_SECRET_ACCESS_KEY }}
      AWS_REGION: us-east-1
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - name: Install local aimodelshare (editable) + test dependencies
        run: |
          pip install boto3 onnx onnxmltools onnxruntime Pympler scikeras shortuuid skl2onnx tf2onnx wget
          pip install -e .
          pip install pytest scikit-learn pandas numpy opencv-python-headless tensorflow pydot regex psutil IPython "PyJWT<2.0" matplotlib seaborn importlib_resources onnxscript
          pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision
      - name: Test model submission + leaderboard retrieval
        run: |
          python -c "
          import seaborn as sns, pandas as pd
          from sklearn.compose import ColumnTransformer
          from sklearn.pipeline import Pipeline
          from sklearn.preprocessing import StandardScaler
          from sklearn.linear_model import LogisticRegression
          from sklearn.model_selection import train_test_split
          from aimodelshare.playground import ModelPlayground
          penguins = sns.load_dataset('penguins').dropna()
          X = penguins[['bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g']]
          y = penguins['sex']
          X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)
          eval_labels = list(y_test)
          preprocess = ColumnTransformer([('num', Pipeline([('scaler', StandardScaler())]), X.columns.tolist())])
          preprocess.fit(X_train)
          def preprocessor(d): return preprocess.transform(d)
          model = LogisticRegression()
          model.fit(preprocessor(X_train), y_train)
          preds = model.predict(preprocessor(X_test))
          playground = ModelPlayground(input_type='tabular', task_type='classification', private=True)
          playground.create(eval_data=eval_labels, public=True)
          playground.submit_model(model=model,
                                  preprocessor=preprocessor,
                                  prediction_submission=preds,
                                  input_dict={'description':'CI test','tags':'integration'},
                                  submission_type='experiment')
          data = playground.get_leaderboard()
          # Depending on library version, this may be a dict or DataFrame; adapt assertion
          if isinstance(data, dict):
              import pandas as pd
              df = pd.DataFrame(data)
              assert not df.empty, 'Leaderboard dict converted to empty DataFrame'
              print(df.head())
          else:
              import pandas as pd
              assert isinstance(data, pd.DataFrame), 'Leaderboard did not return a DataFrame'
              assert not data.empty, 'Leaderboard DataFrame is empty'
              print(data.head())
          print('✓ Leaderboard retrieval test passed')
          "

  test-deployment:
    if: ${{ github.event.inputs.test_step == 'all' || github.event.inputs.test_step == 'deployment' }}
    runs-on: ubuntu-latest
    timeout-minutes: 18
    env:
      USERNAME: ${{ secrets.USERNAME }}
      PASSWORD: ${{ secrets.PASSWORD }}
      AWS_ACCESS_KEY_ID: ${{ secrets.DATA_AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.DATA_AWS_SECRET_ACCESS_KEY }}
      AWS_REGION: us-east-1
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - name: Install local aimodelshare (editable) + test dependencies
        run: |
          pip install boto3 onnx onnxmltools onnxruntime Pympler scikeras shortuuid skl2onnx tf2onnx wget
          pip install -e .
          pip install pytest scikit-learn pandas numpy opencv-python-headless tensorflow pydot regex psutil IPython "PyJWT<2.0" matplotlib seaborn importlib_resources onnxscript
          pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision
      - name: Test deployment workflow
        run: |
          python -c "
          import seaborn as sns, pandas as pd
          from sklearn.compose import ColumnTransformer
          from sklearn.pipeline import Pipeline
          from sklearn.preprocessing import StandardScaler
          from sklearn.linear_model import LogisticRegression
          from sklearn.model_selection import train_test_split
          from aimodelshare.playground import ModelPlayground
          penguins = sns.load_dataset('penguins').dropna()
          X = penguins[['bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g']]
          y = penguins['sex']
          X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)
          y_train_df = pd.get_dummies(y_train)
          eval_labels = list(y_test)
          example_data = X_test.head(5)
          preprocess = ColumnTransformer([('num', Pipeline([('scaler', StandardScaler())]), X.columns.tolist())])
          preprocess.fit(X_train)
          def preprocessor(d): return preprocess.transform(d)
          model = LogisticRegression()
          model.fit(preprocessor(X_train), y_train)
          preds = model.predict(preprocessor(X_test))
        	inputs = [os.environ.get('USERNAME'),
        			  os.environ.get('PASSWORD'),
        			  os.environ.get('AWS_ACCESS_KEY_ID'),
        			  os.environ.get('AWS_SECRET_ACCESS_KEY'),
        			  os.environ.get('AWS_REGION')]
        
        	with patch("getpass.getpass", side_effect=inputs):
        		from aimodelshare.aws import configure_credentials
        		configure_credentials()
        
        	# set credentials
        	set_credentials(credential_file="credentials.txt", type="deploy_model")
        
        	# clean up credentials file
        	os.remove("credentials.txt")

          playground = ModelPlayground(input_type='tabular', task_type='classification', private=True)
          playground.create(eval_data=eval_labels, public=True)
          playground.submit_model(model=model,
                                  preprocessor=preprocessor,
                                  prediction_submission=preds,
                                  input_dict={'description':'deploy test','tags':'deploy'},
                                  submission_type='experiment')
          playground.deploy_model(model_version=1, example_data=example_data, y_train=y_train_df)
          print('✓ Deployment test passed')
          "

  integration-summary:
    needs:
      - test-credentials
      - test-data-loading
      - test-preprocessing
      - test-model-training
      - test-playground-create
      - test-model-submission
      - test-deployment
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Summary
        run: |
          echo "=== Integration Test Summary ==="
          echo "Credentials: ${{ needs.test-credentials.result }}"
          echo "Data Loading: ${{ needs.test-data-loading.result }}"
          echo "Preprocessing: ${{ needs.test-preprocessing.result }}"
          echo "Model Training: ${{ needs.test-model-training.result }}"
          echo "Playground Create: ${{ needs.test-playground-create.result }}"
          echo "Model Submission: ${{ needs.test-model-submission.result }}"
          echo "Deployment: ${{ needs.test-deployment.result }}"
